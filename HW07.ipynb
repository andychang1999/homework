{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.03895727,  0.18817306, -0.25198942,  0.14138648,  0.16928005,\n",
       "          0.01693133,  0.17866623, -0.04920617, -0.02918109,  0.10102469,\n",
       "          0.05259612, -0.10609391,  0.05133298, -0.12643884, -0.06601749,\n",
       "         -0.2950767 , -0.1264111 ,  0.14428613, -0.01032299,  0.26225144,\n",
       "          0.05200171, -0.11939336, -0.24950275,  0.13931543,  0.2224434 ,\n",
       "         -0.11184138,  0.12075511,  0.15555474, -0.22209342, -0.16023876,\n",
       "         -0.2857763 , -0.00475568, -0.14610362, -0.29388207,  0.02091807,\n",
       "         -0.03942758, -0.219684  , -0.19092771, -0.09135175,  0.10967213,\n",
       "          0.27934283,  0.12263039, -0.16063046,  0.13682711,  0.01857686,\n",
       "         -0.158958  ,  0.16312647,  0.03939706, -0.2858604 , -0.04997687,\n",
       "         -0.2244344 ,  0.1405378 ,  0.22913504,  0.1570845 ,  0.09033027,\n",
       "         -0.13279241,  0.06535017, -0.23235089,  0.21899265,  0.00812975,\n",
       "          0.0105744 , -0.19420806, -0.11846456, -0.12176394],\n",
       "        [-0.18269059, -0.08661   ,  0.00527957, -0.15259288, -0.22564289,\n",
       "         -0.15623282,  0.25254196,  0.24337262, -0.20020646,  0.0664326 ,\n",
       "         -0.10986961, -0.2845626 , -0.1835651 ,  0.23921329, -0.10028751,\n",
       "          0.00365928, -0.01551157,  0.15850472, -0.26885632, -0.23197468,\n",
       "         -0.09446736, -0.10659321,  0.22220773, -0.12905537,  0.02510095,\n",
       "         -0.12506877,  0.08868   ,  0.07342064, -0.23786712, -0.2528296 ,\n",
       "          0.17534757, -0.06987125,  0.1326268 , -0.07957608,  0.13641009,\n",
       "          0.14909771, -0.0286375 ,  0.10877335, -0.22616535,  0.19122916,\n",
       "         -0.28847492, -0.12120402, -0.03909767,  0.2293874 ,  0.03567949,\n",
       "          0.21359295, -0.16585852, -0.15677677, -0.16859154, -0.13065748,\n",
       "         -0.09798649,  0.15744835, -0.28577885, -0.102428  ,  0.23914468,\n",
       "          0.19639614, -0.07535081, -0.17356367, -0.21044923,  0.16760838,\n",
       "          0.12013358, -0.22958012,  0.04279476, -0.13335119],\n",
       "        [-0.17593327,  0.13810208, -0.05495685,  0.16755474,  0.14420685,\n",
       "         -0.2114872 , -0.10106549,  0.25337315, -0.07209587,  0.00950184,\n",
       "          0.02856201,  0.23810363, -0.18771923, -0.15312664, -0.15211892,\n",
       "         -0.18872544,  0.23010254,  0.24687952,  0.12015772,  0.27545172,\n",
       "         -0.06552655, -0.19520679, -0.13949129, -0.25492686, -0.07714348,\n",
       "         -0.21218483, -0.0714872 ,  0.08776397,  0.22589093, -0.10901102,\n",
       "          0.255615  , -0.10004686, -0.16214488, -0.13920583, -0.2509623 ,\n",
       "         -0.07032552,  0.16128713, -0.14007348,  0.24136597,  0.24014044,\n",
       "         -0.15286465, -0.17703873,  0.02999768, -0.2071181 ,  0.14504668,\n",
       "          0.04040149, -0.09779321, -0.02715749, -0.2914108 ,  0.22291714,\n",
       "         -0.11307241,  0.28620142,  0.25144684,  0.08180925,  0.22993326,\n",
       "          0.25218415,  0.01578447,  0.22169322, -0.2752267 ,  0.20731682,\n",
       "         -0.03273186,  0.10403061,  0.19559541,  0.04212087]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-2.14999855e-01,  2.28161603e-01, -6.37492537e-02,\n",
       "         -8.65593702e-02, -1.72363013e-01, -2.75091320e-01,\n",
       "          1.51725411e-02,  2.32801110e-01,  7.59665072e-02,\n",
       "          1.88854486e-01],\n",
       "        [-1.34208813e-01, -8.39967728e-02, -2.05293894e-01,\n",
       "          8.60578120e-02,  1.41732961e-01, -1.82709038e-01,\n",
       "          1.84370279e-01,  2.23933309e-01, -2.24667877e-01,\n",
       "          2.73262262e-02],\n",
       "        [ 1.30987763e-01, -1.43873304e-01,  2.24951714e-01,\n",
       "          1.27077103e-04, -2.70488918e-01, -1.78248048e-01,\n",
       "         -6.93543851e-02,  1.99303776e-01, -1.67589188e-01,\n",
       "         -1.53631270e-01],\n",
       "        [-2.13697270e-01, -2.29245424e-01, -2.08113328e-01,\n",
       "         -1.42485842e-01, -6.54426813e-02,  1.33689046e-01,\n",
       "         -2.61710793e-01, -9.37804580e-03, -2.49295041e-01,\n",
       "          1.82893157e-01],\n",
       "        [-8.15140605e-02,  1.15824848e-01,  8.43128562e-03,\n",
       "          1.59774750e-01,  4.65225577e-02,  2.04185009e-01,\n",
       "          5.89522123e-02,  3.85172069e-02,  1.31689668e-01,\n",
       "         -1.17816731e-01],\n",
       "        [ 9.33687091e-02, -8.62842947e-02,  3.39851379e-02,\n",
       "         -8.37436169e-02, -2.43190929e-01,  7.56893158e-02,\n",
       "         -1.02280378e-01,  3.91899943e-02, -1.20737851e-01,\n",
       "         -1.05034173e-01],\n",
       "        [ 1.56838149e-01, -2.67172605e-01, -1.90082461e-01,\n",
       "          2.69905001e-01,  1.14671767e-01,  1.36804819e-01,\n",
       "         -2.46768206e-01,  1.21864676e-01,  2.25107104e-01,\n",
       "          1.55408382e-02],\n",
       "        [ 7.69953728e-02,  2.01526195e-01, -1.91358447e-01,\n",
       "         -7.18844086e-02, -1.86295062e-01, -1.17195338e-01,\n",
       "         -2.66277015e-01,  1.13753557e-01, -1.96030498e-01,\n",
       "         -2.18938515e-01],\n",
       "        [ 3.10828686e-02, -2.10522711e-02, -4.81985211e-02,\n",
       "          2.24624842e-01,  3.98328900e-02, -2.60072500e-01,\n",
       "          2.66371399e-01,  1.93362474e-01,  5.40896058e-02,\n",
       "         -4.91378307e-02],\n",
       "        [-1.49954528e-01, -1.16454661e-01,  2.43297726e-01,\n",
       "         -7.53789991e-02, -7.19983876e-02, -2.05443203e-02,\n",
       "          1.74110532e-01,  2.02344328e-01,  2.06020236e-01,\n",
       "          2.24769086e-01],\n",
       "        [-1.73228472e-01,  2.66924798e-02, -1.76467314e-01,\n",
       "         -1.83697045e-02, -9.07970816e-02,  6.09559715e-02,\n",
       "         -1.89796984e-01, -2.23038137e-01,  8.51117074e-02,\n",
       "         -5.74725717e-02],\n",
       "        [ 1.27964914e-02,  2.00771064e-01, -2.81624287e-01,\n",
       "          2.00714648e-01, -5.26279509e-02, -6.00077659e-02,\n",
       "          1.02693737e-02,  2.74990112e-01, -1.20618507e-01,\n",
       "         -4.34886515e-02],\n",
       "        [ 1.80715322e-02,  2.71801949e-02,  2.18611091e-01,\n",
       "          2.37919062e-01, -2.15196908e-02, -1.84363082e-01,\n",
       "          2.29773253e-01,  1.82089001e-01, -9.53519642e-02,\n",
       "          7.67562091e-02],\n",
       "        [-2.81771213e-01,  2.49038935e-02,  9.24995542e-03,\n",
       "         -6.82320446e-02,  4.44154739e-02, -4.51442003e-02,\n",
       "          4.11906838e-02, -9.02649611e-02, -2.61963695e-01,\n",
       "         -5.77684343e-02],\n",
       "        [-1.16844893e-01,  1.32067859e-01,  1.64575398e-01,\n",
       "         -5.20183742e-02,  2.01768011e-01,  2.19980687e-01,\n",
       "         -1.05740011e-01,  1.78107589e-01,  1.80128783e-01,\n",
       "          1.45848811e-01],\n",
       "        [ 8.39218795e-02,  3.67110074e-02,  7.38129914e-02,\n",
       "          1.61869615e-01, -1.66511863e-01,  2.94511020e-02,\n",
       "          2.57854491e-01, -2.64183044e-01,  2.77987421e-02,\n",
       "          4.86547351e-02],\n",
       "        [ 2.28146762e-01,  2.14123607e-01, -2.11042345e-01,\n",
       "          2.81765431e-01, -8.95132273e-02,  2.11983740e-01,\n",
       "         -1.32043287e-01, -7.46420622e-02,  1.74847335e-01,\n",
       "         -1.81757569e-01],\n",
       "        [ 2.46131152e-01, -8.09362680e-02,  1.98522508e-01,\n",
       "          2.53901511e-01,  2.83279985e-01, -2.62058854e-01,\n",
       "         -2.52854824e-02, -2.18931451e-01, -8.76078606e-02,\n",
       "         -2.75524259e-01],\n",
       "        [-8.39281976e-02, -1.60040051e-01,  5.00057340e-02,\n",
       "          2.35514045e-02,  4.84070182e-02,  1.26437336e-01,\n",
       "          2.03158319e-01,  2.67776847e-02, -1.20904192e-01,\n",
       "          1.37655616e-01],\n",
       "        [-1.42797261e-01, -2.15464354e-01,  1.43608451e-01,\n",
       "          2.06194788e-01, -1.76616803e-01, -8.06802511e-02,\n",
       "          2.32812792e-01, -2.29752362e-02, -8.50508809e-02,\n",
       "          2.33927518e-01],\n",
       "        [ 1.62598997e-01, -1.99244708e-01,  7.11598992e-03,\n",
       "         -4.88045663e-02,  2.32032865e-01,  2.59076953e-02,\n",
       "         -1.36963949e-01, -2.49003261e-01, -2.05138564e-01,\n",
       "         -9.18172449e-02],\n",
       "        [-2.65528470e-01, -2.12733045e-01, -8.74391496e-02,\n",
       "         -2.32710287e-01, -1.81034207e-01, -3.40789557e-04,\n",
       "          1.38044327e-01,  2.07391322e-01,  7.25605786e-02,\n",
       "          1.06256425e-01],\n",
       "        [-1.46076024e-01,  1.47970319e-02,  6.25377893e-02,\n",
       "         -1.81491852e-01, -1.66445464e-01, -7.35119879e-02,\n",
       "         -2.61620164e-01, -1.43884018e-01,  2.74114937e-01,\n",
       "          1.07235134e-01],\n",
       "        [-1.48740113e-02,  1.72059357e-01, -5.13041019e-02,\n",
       "         -1.29717946e-01, -1.65685415e-02, -2.31560037e-01,\n",
       "          2.83008605e-01, -1.82877198e-01, -2.54853874e-01,\n",
       "          1.69749409e-01],\n",
       "        [-9.69830155e-03, -2.06369877e-01, -2.68546611e-01,\n",
       "         -2.09608972e-02,  1.52716190e-01, -2.22367734e-01,\n",
       "          1.20117277e-01,  2.74525613e-01, -1.64494738e-01,\n",
       "          1.76732153e-01],\n",
       "        [ 1.58061832e-01, -1.09208941e-01, -1.60964504e-01,\n",
       "         -3.63928825e-02, -8.14476013e-02, -1.37650385e-01,\n",
       "          1.49535835e-02, -2.65053332e-01, -3.38327289e-02,\n",
       "         -1.97724402e-01],\n",
       "        [ 2.82098264e-01,  2.13550836e-01,  1.10629052e-01,\n",
       "          2.54055649e-01,  1.68086618e-01, -1.99739933e-02,\n",
       "         -2.59452879e-01, -2.70235211e-01,  1.02397203e-01,\n",
       "          3.07470858e-02],\n",
       "        [ 5.81477284e-02, -2.20825016e-01, -1.52793914e-01,\n",
       "          6.02478087e-02, -2.81658858e-01, -2.61568904e-01,\n",
       "         -2.42482305e-01, -2.53261626e-02, -1.22701555e-01,\n",
       "         -1.58306360e-02],\n",
       "        [-2.11092919e-01,  2.13695228e-01,  1.44627541e-01,\n",
       "          4.72661257e-02,  1.33392394e-01, -6.40967190e-02,\n",
       "          2.43319780e-01,  2.36916274e-01,  2.46897668e-01,\n",
       "          1.46377683e-02],\n",
       "        [-6.69099092e-02, -5.77356517e-02,  2.06706792e-01,\n",
       "          1.76481426e-01,  1.49477601e-01,  2.56712943e-01,\n",
       "          1.17080957e-01,  2.02420831e-01, -7.96725750e-02,\n",
       "          1.36767566e-01],\n",
       "        [-9.80541110e-03, -2.37791643e-01,  2.04974115e-02,\n",
       "         -2.00111449e-01, -1.43554688e-01, -1.83982491e-01,\n",
       "         -2.55580157e-01, -2.21829712e-02, -3.59390527e-02,\n",
       "         -2.61856288e-01],\n",
       "        [ 1.72307402e-01, -1.96630359e-02,  2.75789469e-01,\n",
       "         -1.83330566e-01,  2.37550586e-01, -2.00583011e-01,\n",
       "          3.43866348e-02, -1.68306574e-01,  2.60096639e-01,\n",
       "         -1.64152771e-01],\n",
       "        [-1.69326678e-01, -1.75482377e-01,  1.11780435e-01,\n",
       "          2.15928555e-02, -2.42567718e-01,  2.23826855e-01,\n",
       "         -4.15679961e-02, -2.32627332e-01, -2.23762646e-01,\n",
       "          1.00318730e-01],\n",
       "        [ 4.98845577e-02, -1.45867467e-01,  2.80617923e-01,\n",
       "          7.12719560e-03,  2.37741619e-01, -2.39201158e-01,\n",
       "          2.17845410e-01,  2.82051593e-01, -2.30704233e-01,\n",
       "          1.30604386e-01],\n",
       "        [-8.17787647e-02,  1.53188765e-01,  4.91321087e-04,\n",
       "          4.81755733e-02, -9.62112397e-02,  2.43169069e-02,\n",
       "         -1.32902756e-01,  2.77611822e-01,  1.95795953e-01,\n",
       "          2.81756967e-01],\n",
       "        [-1.15674287e-01,  1.25278890e-01, -9.04331207e-02,\n",
       "         -2.65661538e-01,  1.67086422e-02,  2.21868187e-01,\n",
       "         -9.12537724e-02,  2.20965445e-02, -2.08736628e-01,\n",
       "         -1.97005451e-01],\n",
       "        [-2.64350325e-01,  2.49370009e-01,  1.78343564e-01,\n",
       "         -1.60777003e-01,  5.85296750e-02, -2.91447043e-02,\n",
       "         -4.04891372e-03,  4.15179133e-02,  2.77281553e-01,\n",
       "         -4.70888019e-02],\n",
       "        [ 1.32425696e-01,  2.83623010e-01,  2.81295776e-02,\n",
       "          1.41994476e-01,  2.82937884e-02,  5.54628670e-02,\n",
       "          5.79920113e-02, -2.04483032e-01, -8.74229223e-02,\n",
       "          2.28599399e-01],\n",
       "        [ 2.35319287e-01, -2.78527409e-01,  1.45123214e-01,\n",
       "          1.08911693e-02,  5.11841476e-02, -8.48076344e-02,\n",
       "          1.57504618e-01, -3.52617800e-02,  1.29770488e-01,\n",
       "         -5.79887629e-03],\n",
       "        [-3.06331217e-02, -2.79531270e-01,  2.14031368e-01,\n",
       "          4.26749885e-02, -1.87302619e-01, -2.52448976e-01,\n",
       "         -2.03795925e-01, -2.08917856e-02, -2.21963316e-01,\n",
       "         -1.58049628e-01],\n",
       "        [ 1.82482690e-01, -1.73062742e-01,  2.43370444e-01,\n",
       "         -5.67302853e-02,  1.26687586e-01,  4.52152789e-02,\n",
       "         -9.94353592e-02,  1.72704577e-01,  6.50958419e-02,\n",
       "         -1.82593420e-01],\n",
       "        [-1.92674473e-01, -7.59447217e-02,  7.65854418e-02,\n",
       "         -2.03720227e-01,  2.37166315e-01, -2.04596400e-01,\n",
       "         -1.68505892e-01,  1.20398551e-01, -6.45116568e-02,\n",
       "         -2.09476203e-01],\n",
       "        [-1.83093756e-01,  9.44739580e-02, -3.96231115e-02,\n",
       "          1.36865079e-02, -2.69731015e-01, -1.67813897e-03,\n",
       "         -3.24656367e-02,  4.56437469e-03,  1.09000981e-01,\n",
       "         -1.02750987e-01],\n",
       "        [-2.20452309e-01,  2.74271816e-01,  1.91415727e-01,\n",
       "         -1.78423405e-01,  1.60046369e-01,  1.31324261e-01,\n",
       "          2.18297273e-01, -8.57894421e-02,  1.88371241e-02,\n",
       "          2.72548050e-01],\n",
       "        [-2.16145352e-01, -2.44013816e-01, -8.13429207e-02,\n",
       "          2.29853362e-01, -9.74923670e-02,  1.00597560e-01,\n",
       "          6.07350469e-02, -6.10810816e-02,  2.45948434e-02,\n",
       "         -1.94457442e-01],\n",
       "        [ 1.65002346e-01,  2.87947357e-02,  1.60982639e-01,\n",
       "         -2.79292971e-01,  2.37893671e-01,  3.94699574e-02,\n",
       "          1.42196923e-01, -1.66641533e-01, -1.09233722e-01,\n",
       "          1.86093986e-01],\n",
       "        [ 1.02785259e-01,  2.53350884e-01, -1.70743927e-01,\n",
       "          1.23932034e-01, -1.81972980e-01,  1.07272744e-01,\n",
       "         -1.01394907e-01,  3.81214917e-02,  2.80916095e-02,\n",
       "          8.56465995e-02],\n",
       "        [ 1.43314242e-01, -1.72186911e-01,  2.19422877e-02,\n",
       "          1.79544330e-01, -1.33523002e-01, -6.29388690e-02,\n",
       "         -2.03562379e-01, -3.69051099e-03,  1.26989841e-01,\n",
       "         -2.33688951e-03],\n",
       "        [ 9.73210931e-02, -2.48515546e-01, -2.49454036e-01,\n",
       "          3.73003483e-02, -5.51968068e-02, -1.46939442e-01,\n",
       "         -6.94385022e-02, -1.46910176e-01,  2.48527557e-01,\n",
       "         -3.85207981e-02],\n",
       "        [-2.24990413e-01, -1.27779588e-01, -1.94305301e-01,\n",
       "         -1.45712197e-02, -8.99669379e-02, -1.96066201e-01,\n",
       "          6.46524429e-02,  1.35564566e-01, -2.65546322e-01,\n",
       "          1.58061355e-01],\n",
       "        [ 1.17583334e-01, -1.77632689e-01,  1.84502870e-01,\n",
       "          2.32601464e-02, -5.53442538e-02,  1.17332876e-01,\n",
       "          1.37382835e-01, -2.22600177e-01, -8.07085633e-03,\n",
       "         -1.92010105e-02],\n",
       "        [ 9.84370708e-05, -8.21725279e-02, -1.34774148e-02,\n",
       "         -1.38678625e-01, -2.55981088e-03, -1.77437857e-01,\n",
       "         -2.63271421e-01,  8.64901841e-02, -6.33594394e-03,\n",
       "         -8.99523497e-03],\n",
       "        [ 4.84488308e-02, -2.53168941e-01,  2.56151766e-01,\n",
       "          1.80189133e-01,  8.37788582e-02, -1.40368938e-01,\n",
       "         -1.72817796e-01, -2.66797841e-02,  4.97341156e-02,\n",
       "          1.20802134e-01],\n",
       "        [-1.94661528e-01, -7.80384094e-02,  5.88557422e-02,\n",
       "         -1.54879391e-02,  3.41874361e-03, -1.29506886e-01,\n",
       "         -2.13894218e-01, -4.82386500e-02, -9.76036340e-02,\n",
       "         -4.87771481e-02],\n",
       "        [ 3.65690589e-02,  2.13272274e-01,  2.38845438e-01,\n",
       "         -1.89004719e-01,  2.04022884e-01, -1.38906673e-01,\n",
       "          6.21354580e-02,  2.23518938e-01,  2.76728868e-02,\n",
       "         -1.50047943e-01],\n",
       "        [-1.42029017e-01,  1.54037774e-01, -3.83844078e-02,\n",
       "          2.02761501e-01, -4.41509485e-03,  1.73946053e-01,\n",
       "         -2.67781854e-01,  1.97649449e-01,  1.59902871e-01,\n",
       "         -1.29898056e-01],\n",
       "        [-1.08349025e-02,  1.13638371e-01,  9.61846113e-02,\n",
       "         -1.84335649e-01, -1.57098085e-01,  2.56624430e-01,\n",
       "         -2.28510499e-02, -2.84593880e-01, -1.79817379e-01,\n",
       "         -1.25600994e-02],\n",
       "        [ 1.80231899e-01, -1.76861271e-01,  2.09320128e-01,\n",
       "         -1.66812599e-01,  5.81814647e-02, -9.48364139e-02,\n",
       "         -1.14511684e-01, -4.81122434e-02, -2.74297297e-01,\n",
       "         -9.02903080e-03],\n",
       "        [ 3.14493477e-02, -7.91075379e-02,  2.08924890e-01,\n",
       "          4.41699326e-02, -2.17768043e-01, -1.09148711e-01,\n",
       "         -1.71637416e-01,  4.16868031e-02,  1.42033905e-01,\n",
       "          1.66408747e-01],\n",
       "        [ 7.41401613e-02,  4.88335490e-02, -1.90490693e-01,\n",
       "          1.08107775e-01, -1.05823785e-01, -2.22279400e-01,\n",
       "         -9.58482325e-02, -1.27782166e-01,  6.47466183e-02,\n",
       "          2.51493722e-01],\n",
       "        [-1.10449135e-01,  1.36491597e-01, -1.17894530e-01,\n",
       "          1.66024685e-01, -2.20976681e-01, -1.11146554e-01,\n",
       "          1.84866428e-01, -5.39239496e-02,  2.13193059e-01,\n",
       "          2.05281615e-01],\n",
       "        [-1.48533002e-01,  2.01790273e-01,  1.81517839e-01,\n",
       "          1.83202922e-01,  2.23267525e-01, -2.82207191e-01,\n",
       "         -2.13149205e-01,  7.78845251e-02,  1.13834769e-01,\n",
       "         -1.09808534e-01],\n",
       "        [-1.97383463e-01,  6.48987591e-02,  1.14585876e-01,\n",
       "         -1.08123794e-01, -2.56604850e-01, -1.45664006e-01,\n",
       "         -9.26360488e-03,  9.28187370e-02,  2.46788532e-01,\n",
       "         -2.29720175e-01],\n",
       "        [-1.00357220e-01, -6.17951453e-02,  2.30100244e-01,\n",
       "          1.65599644e-01, -1.45459533e-01,  2.43316501e-01,\n",
       "          2.03595251e-01, -2.26128578e-01, -2.55634248e-01,\n",
       "         -2.67777979e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 16ms/step - loss: 32.5760 - priority_loss: 0.3152 - department_loss: 32.2609 - priority_mean_absolute_error: 0.4793 - department_accuracy: 0.2516\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 30.0943 - priority_loss: 0.2147 - department_loss: 29.8796 - priority_mean_absolute_error: 0.3818 - department_accuracy: 0.2523\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 17ms/step - loss: 43.2234 - priority_loss: 0.3319 - department_loss: 42.8915 - priority_mean_absolute_error: 0.4955 - department_accuracy: 0.2523\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 55.6217 - priority_loss: 0.3435 - department_loss: 55.2781 - priority_mean_absolute_error: 0.5068 - department_accuracy: 0.5789\n",
      "40/40 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x293b6163430>,\n",
       " <keras.engine.input_layer.InputLayer at 0x293b6163490>,\n",
       " <keras.engine.input_layer.InputLayer at 0x293b6163460>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x293b6163df0>,\n",
       " <keras.layers.core.dense.Dense at 0x293b6163ac0>,\n",
       " <keras.layers.core.dense.Dense at 0x293b6163280>,\n",
       " <keras.layers.core.dense.Dense at 0x293b61621c0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 18ms/step - loss: 36.1282 - output_1_loss: 0.3215 - output_2_loss: 35.8067 - output_1_mean_absolute_error: 0.4853 - output_2_accuracy: 0.2258\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 43.5111 - output_1_loss: 0.3298 - output_2_loss: 43.1813 - output_1_mean_absolute_error: 0.4932 - output_2_accuracy: 0.5789\n",
      "40/40 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2946 - accuracy: 0.9119 - val_loss: 0.1635 - val_accuracy: 0.9540\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1661 - accuracy: 0.9538 - val_loss: 0.1308 - val_accuracy: 0.9656\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1433 - accuracy: 0.9626 - val_loss: 0.1073 - val_accuracy: 0.9714\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9745\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2958 - accuracy: 0.9130 - rmse: 7.1851 - val_loss: 0.1519 - val_accuracy: 0.9555 - val_rmse: 7.3570\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1636 - accuracy: 0.9532 - rmse: 7.3551 - val_loss: 0.1260 - val_accuracy: 0.9661 - val_rmse: 7.4067\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1392 - accuracy: 0.9622 - rmse: 7.3893 - val_loss: 0.1151 - val_accuracy: 0.9704 - val_rmse: 7.4162\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9714 - rmse: 7.4318\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2932 - accuracy: 0.9136 - val_loss: 0.1467 - val_accuracy: 0.9577\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1631 - accuracy: 0.9534 - val_loss: 0.1233 - val_accuracy: 0.9652\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1388 - accuracy: 0.9625 - val_loss: 0.1081 - val_accuracy: 0.9705\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1258 - accuracy: 0.9683 - val_loss: 0.1103 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1170 - accuracy: 0.9705 - val_loss: 0.1121 - val_accuracy: 0.9735\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1088 - accuracy: 0.9737 - val_loss: 0.1097 - val_accuracy: 0.9745\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1048 - accuracy: 0.9756 - val_loss: 0.1108 - val_accuracy: 0.9768\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0982 - accuracy: 0.9767 - val_loss: 0.1187 - val_accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0986 - accuracy: 0.9775 - val_loss: 0.1203 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293be28da00>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2938 - accuracy: 0.9134 - val_loss: 0.1522 - val_accuracy: 0.9569\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1655 - accuracy: 0.9539 - val_loss: 0.1185 - val_accuracy: 0.9671\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1415 - accuracy: 0.9616 - val_loss: 0.1094 - val_accuracy: 0.9719\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1279 - accuracy: 0.9668 - val_loss: 0.1084 - val_accuracy: 0.9724\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1171 - accuracy: 0.9709 - val_loss: 0.1130 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1142 - accuracy: 0.9719 - val_loss: 0.1118 - val_accuracy: 0.9745\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1046 - accuracy: 0.9747 - val_loss: 0.1125 - val_accuracy: 0.9740\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1024 - accuracy: 0.9761 - val_loss: 0.1070 - val_accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1016 - accuracy: 0.9774 - val_loss: 0.1119 - val_accuracy: 0.9776\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0926 - accuracy: 0.9787 - val_loss: 0.1164 - val_accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293c121d070>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2935 - accuracy: 0.9115 - val_loss: 0.1495 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1662 - accuracy: 0.9531 - val_loss: 0.1253 - val_accuracy: 0.9648\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1392 - accuracy: 0.9622 - val_loss: 0.1162 - val_accuracy: 0.9685\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1247 - accuracy: 0.9668 - val_loss: 0.1149 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1171 - accuracy: 0.9704 - val_loss: 0.1157 - val_accuracy: 0.9722\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1115 - accuracy: 0.9739 - val_loss: 0.1167 - val_accuracy: 0.9757\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1052 - accuracy: 0.9750 - val_loss: 0.1075 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1005 - accuracy: 0.9764 - val_loss: 0.1152 - val_accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1005 - accuracy: 0.9775 - val_loss: 0.1234 - val_accuracy: 0.9781\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0935 - accuracy: 0.9788 - val_loss: 0.1203 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293bf690640>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b73dbdab354e1d3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b73dbdab354e1d3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9128\n",
      "...loss: 0.2906\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9544\n",
      "...loss: 0.1660\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9639\n",
      "...loss: 0.1388\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9676\n",
      "...val_loss: 0.1293\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9676\n",
      "...val_loss: 0.1293\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2954\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1633\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293b65d1fa0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.9135\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1644 - sparse_categorical_accuracy: 0.9549\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1375 - sparse_categorical_accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293bfa7a820>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a Sequential model and add layers one at a time until we are happy with our network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected layers are defined using the Dense class. You can specify the number of neurons or nodes in the layer as the first argument and the activation function using the activation argument.\n",
    "\n",
    "Also, you will use the rectified linear unit activation function referred to as ReLU on the first two layers and the Sigmoid function in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編譯keras\n",
    "指定用於評估一組權重的損失函數、用於搜索網絡不同權重的優化器，以及您希望在訓練期間收集和報告的任何可選指標。\n",
    "\n",
    "在這種情況下，使用交叉熵作為損失參數。這種損失是針對二元分類問題的，在 Keras 中定義為“ binary_crossentropy ”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後通過metrics參數定義的分類準確度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 擬合 Keras 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通過調用模型上的fit()函數來訓練或擬合模型。\n",
    "\n",
    "訓練發生在 epoch 上，每個 epoch 被分成批次。\n",
    "\n",
    "Epoch：一次遍歷訓練數據集中的所有行\n",
    "Batch：在權重更新之前，模型在一個時期內考慮的一個或多個樣本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評估 Keras 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用evaluate()函數在訓練數據集上評估模型，並將用於訓練模型的相同輸入和輸出傳遞給它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict\n",
    "進行預測就像在模型上調用predict()函數一樣簡單。在輸出層上使用了 sigmoid 激活函數，因此預測將是介於 0 和 1 之間的概率。可以通過四捨五入輕鬆地將它們轉換為此分類任務的清晰二進制預測。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "...\n",
    "# make probability predictions with the model\n",
    "predictions = model.predict(X)\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
